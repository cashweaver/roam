:PROPERTIES:
:ROAM_REFS: [cite:@alexanderSocraticGrilling2020]
:ID:       cb4ba655-dabf-40a2-95e7-0cdbff887074
:DIR:      /usr/local/google/home/cashweaver/proj/roam/attachments/cb4ba655-dabf-40a2-95e7-0cdbff887074
:END:
#+title: Scott Alexander | Socratic Grilling
#+author: Cash Weaver
#+date: [2022-02-07 Mon 07:03]
#+startup: overview
#+filetags: :reference:
#+hugo_auto_set_lastmod: t
 
[[id:e7e4bd59-fa63-49a8-bfca-6c767d1c2330][Scott Alexander]], [cite:@alexanderSocraticGrilling2020]

* Summary
* Thoughts
* TODO Notes
#+begin_quote
One of the most important rationalist skills is “noticing your confusion”. But that depends on an even more important proto-skill of wanting things to make sense. If you lose that skill – if it stops bothering you and seeming like a problem when things don’t make sense to you – you will never notice your confusion and you will never become a good scientist or a good anything-else-that-requires-independent-thought. And interpreting an attempt to explore dissonance as a status grab that needs to be knocked down is absolutely fatal for that skill. Instead, you need to think of it as Socratic grilling – like Socratic questioning, but a little harsher and more confrontational in order to get to the point more quickly.

Tolerating this is harder than it sounds. Most people can stay helpful for one or two iterations. But most people are bad at explaining things, so one or two iterations isn’t always enough I’ve had times when I need five or ten question-answer rounds with a teacher in order to understand what they’re telling me. The process sounds a lot like “The thing you just said is obviously wrong”…”no, that explanation you gave doesn’t make sense, you’re still obviously wrong”…”you keep saying the same thing over and over again, and it keeps being obviously wrong”…”no, that’s irrelevant to the point that’s bothering me”…”no, that’s also irrelevant, you keep saying an obviously wrong thing”…”Oh! That word means something totally different from what I thought it meant, now your statement makes total sense.”

But it’s harder even than that. Sometimes there is a vast [[https://www.lesswrong.com/posts/HLqWn5LASfhhArZ7w/expecting-short-inferential-distances][inferential distance]] between you and the place where your teacher’s model makes sense, and you need to go through a process as laborious as converting a religious person to a materialist worldview (or vice versa) before the gap gets closed. The process of learning to really appreciate communism, or libertarianism, or whatever, coming from a diametrically opposed philosophy, looks a lot like dozens of questions about “but isn’t that an atrocity?” “wouldn’t this inevitably lead to dystopia?” and hearing what your interlocutor has to answer. It’s so, so tempting to round this off to them trying to gotcha you (as indeed sometimes it will be) and assume they’re not really committed to trying to understand.
#+end_quote
#+print_bibliography:
